meta = out$meta, uncertainty = "Global")
summary(prep, topics=1)
plot(TenFit, type = "summary", xlim = c(0, .3))
#K = 15
FifFit <- stm(documents = out$documents, vocab = out$vocab,
K = 15, prevalence =~ Mother  + Newspaper + Year ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
labelTopics(FifFit)
topics<-labelTopics(FifFit, c(1:15))
out$meta$Mother <- as.factor(out$meta$Mother)
prep <- estimateEffect(1:15 ~ Mother + Newspaper + Year, FifFit,
meta = out$meta, uncertainty = "Global")
summary(prep, topics=1)
plot(FifFit, type = "summary", xlim = c(0, .3))
summary(prep, topics=1)
out$meta$Mother <- as.factor(out$meta$Mother)
prep <- estimateEffect(1:15 ~ Mother + Newspaper + Year, FifFit,
meta = out$meta, uncertainty = "Global")
prep <- estimateEffect(1:15 ~ Mother + Newspaper + Year, FifFit,
meta = out$meta, uncertainty = "Global")
summary(prep, topics=1)
labelTopics(FifFit)
#K = 15
FifFit <- stm(documents = out$documents, vocab = out$vocab,
K = 15, content =~ Mother  + Newspaper + Year ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
#K = 15
FifFit <- stm(documents = out$documents, vocab = out$vocab,
K = 15, content =~ Mother ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
#K = 15, tried to run with content covariate but it takes too lomg- francis laptop needs to try if we feel the need
FifFit <- stm(documents = out$documents, vocab = out$vocab,
K = 15, content =~ Mother ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
#K = 15, tried to run with content covariate but it takes too lomg- francis laptop needs to try if we feel the need
FifFit <- stm(documents = out$documents, vocab = out$vocab,
K = 15, prevalence =~ Mother + Year + Newspaper,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
#K = 30
ThiFit <- stm(documents = out$documents, vocab = out$vocab,
K = 30, prevalence =~ Mother  + Newspaper + Year ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
labelTopics(ThiFit)
#create document feature matrix for mother and father separately
m<- data %>%
filter(Mother=="TRUE")
f<- data %>%
filter(Mother=="FALSE")
dfm_prep<- function(x) {
x$Text1%>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens(remove_punc=TRUE) %>%
tokens_remove(stopwords("English")) %>%
tokens_remove(c("said", "like", "just", "can", "go", "one", "say", "also", "want", "told", "get", "say ", "two", "make")) #frequent non interesting words
}
#dfm<- dfm_prep(data)
dfmm<- dfm_prep(m) %>%
tokens_wordstem(language = quanteda_options("language_stemmer")) %>%
tokens_remove(c("s")) %>%
dfm() %>%
dfm_trim(min_termfreq = 5)
dfmf<- dfm_prep(f) %>%
tokens_wordstem(language = quanteda_options("language_stemmer")) %>%
tokens_remove(c("s")) %>%
dfm() %>%
dfm_trim(min_termfreq = 5)
#no
freq<- function(x){
a<- x %>% textstat_frequency() %>% head(20)
a$feature<- factor(a$feature, levels=a$feature)
ggplot(a, aes(x=frequency, y=feature, fill=docfreq)) +
geom_col() #+ ggtitle("Most frequent words around the word Mother")
a
ggsave("plot.png", a,  width=2, height=2)
}
#freq(dfmf)
#plot for mother
freq<- dfmm %>% textstat_frequency() %>% head(20)
freq$feature<- factor(freq$feature, levels=freq$feature)
a<- ggplot(freq, aes(x=frequency, y=feature, fill=docfreq)) +
geom_col() + ggtitle("Most frequent words around the word Mother")
a
ggsave("dfmm.png", a,  width=2, height=2)
#plot for father
freq<- dfmf %>% textstat_frequency() %>% head(20)
freq$feature<- factor(freq$feature, levels=freq$feature)
a<- ggplot(freq, aes(x=frequency, y=feature, fill=docfreq)) +
geom_col() + ggtitle("Most frequent words around the word Father")
a
ggsave("dfmf.png", a,  width=2, height=2)
#cloudmapper mother - does not work!!
set.seed(1234) # for reproducibility
wordcloud(words = dfmm$feature, freq = dfmm$frequency, min.freq = 1, max.words=20, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
processed <- textProcessor(data$Text1, metadata = data)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta
?future_map
??future_map
library(furrr)
many_models <- data_frame(K = c(10, 15, 20, 30, 40)) %>%
mutate(topic_model = future_map(K, ~stm(documents = out$documents,
vocab = out$vocab,
K = .,
prevalence =~ Mother + Newspaper + Year ,
max.em.its = 75,
data = out$meta,
init.type = "Spectral")))
many_models <- tibble(K = c(10, 15, 20, 30, 40)) %>%
mutate(topic_model = future_map(K, ~stm(documents = out$documents,
vocab = out$vocab,
K = .,
prevalence =~ Mother + Newspaper + Year ,
max.em.its = 75,
data = out$meta,
init.type = "Spectral")))
library(furrr)
many_models <- tibble(K = c(10, 15, 20, 30, 40)) %>%
mutate(topic_model = future_map(K, ~stm(documents = out$documents,
vocab = out$vocab,
K = .,
prevalence =~ Mother + Newspaper + s(Year) ,
max.em.its = 75,
data = out$meta,
init.type = "Spectral")))
terms(ThiFit, 30)
prep <- estimateEffect(1:15 ~ Mother + Newspaper + Year, FifFit,
meta = out$meta, uncertainty = "Global")
summary(prep, topics=1)
plot(FifFit, type = "summary", xlim = c(0, .3))
?calcfrex
?calcscore
?calclift
#K = 50
FiftFit <- stm(documents = out$documents, vocab = out$vocab,
K = 50, prevalence =~ Mother  + Newspaper + Year ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
labelTopics(FiftFit)
load("/Users/marenrieker/Documents/GitHub/TM-mother-father/data.RData")
knitr::opts_chunk$set(echo = TRUE)
load(file = "data.RData")
nrow(is.na(data@meta$Date)) #check that there are no missing dates
data[duplicated(data@articles$Article), ] #check if there are direct duplicates (there are 52)
data <- data[!duplicated(data@articles$Article), ] #remove direct duplicates
nrow(is.na(data@meta$Date))
##calculate distance (takes several minutes) - converts into dtm, compares articles published on same day, and calculates overlap
duplicates_data <- lnt_similarity(LNToutput =  data, #this is the same as similarity measure from quanteda, if rel-dist = off
threshold = 0.95,
rel_dist = F) #no Levenstein distance calculated - much faster
#validate
head(duplicates_data[order(duplicates_data$Similarity), ], n = 1)
duplicates_data[11]
data <- data[!data@meta$ID %in% duplicates_data$ID_duplicate, ] #remove duplicates
nrow(data) #4617 articles left
head(data@meta)
save(data, file = "data.RData") #save LNToutput
load(file = "data.RData")
data@meta[8,]
data@meta[data@meta$Newspaper == "March 20, 2009", ] #Times London, Times London, Times London
library(tidyverse)
data@meta <- data@meta %>%
mutate(Newspaper = recode(Newspaper,
"The Guardian(London)" = "The Guardian",
"The Times (London)" = "The Times",
"Daily Mail (London)" = "Daily Mail",
"The Guardian (London)" = "The Guardian",
"Guardian.com" = "The Guardian",
"DAILY MAIL (London)" = "Daily Mail",
"The Guardian (London) - Final Edition" = "The Guardian",
"May 4, 2012" = "The Times",
"The Guardian - Final Edition" = "The Guardian",
"Mail on Sunday (London)" = "Daily Mail",
"MAIL ON SUNDAY (London)" = "Daily Mail",
"March 20, 2009" = "The Times",
"MAIL ON SUNDAY" = "Daily Mail",
"March 27, 2009" = "The Times",
"Guardian.com." = "The Times",
"June 21, 2011" = "The Times",
"March 26, 2009"= "The Times",
"March 25, 2009" = "The Times",
"May 22, 2012" = "The Times",
"February 13, 2009" = "The Times",
"February 17, 2009" = "The Times",
"March 5, 2009" = "The Times",
"March 18, 2009" = "The Times",
"January 21, 2009" = "The Times",
"March 13, 2009" = "The Times",
"March 20, 2012" = "The Times",
"March 24, 2009" = "The Times",
"March 9, 2009" = "The Times",
"March 15, 2009" = "The Times",
"February 12, 2009" = "The Times",
"March 22, 2009"= "The Times",
"February 18, 2009" = "The Times",
"March 21, 2009" = "The Times",
"March 15, 2012" = "The Times",
"March 16, 2009" = "The Times",
"March 17, 2012" = "The Times",
"September 9, 2010" = "The Times",
"March 8, 2009" = "The Times",
"May 25, 2012" = "The Times",
"September 11, 2010" = "The Times",
"February 5, 2009" = "The Times",
"February 16, 2009" = "The Times",
"March 4, 2009" = "The Times",
"March 14, 2009" = "The Times",
"March 19, 2009" = "The Times",
"October 13, 2010" = "The Times",
"April 6, 2009" = "The Times"))
unique(data@meta$Newspaper)
data@meta$Date
##Split Year variable
data@meta <- data@meta %>%
dplyr::mutate(Year = lubridate::year(Date),
Month = lubridate::month(Date),
Day = lubridate::day(Date))
head(data@paragraphs)
# ##make Paragraph ID
# data$Par_ID <- with(data, paste0(Par_ID, Newspaper, Headline, Year))
# ##drop unnecessary columns
# data <- subset(data, select = -c(Edition, Graphic, Source_File))
# meta_articles <- lnt_convert(data, to = "data.frame") #keep only one df
#meta_paragraphs
mp <- lnt_convert(data, to = "data.frame", what = "Paragraphs")
##-------------------- remove irrelavnt infor paragraphs
##make dfs that include relevant paragraphs
lang <- mp[grep("Language:", mp$Paragraph), ]
publ <- mp[grep("Publication-Type:", mp$Paragraph), ]
classi <- mp[grep("Classification", mp$Paragraph), ]
subj <- mp[grep("Subject:", mp$Paragraph), ]
indust <- mp[grep("Industry:", mp$Paragraph), ]
geo <- mp[grep("Geographic:", mp$Paragraph), ]
pers <- mp[grep("Person:", mp$Paragraph), ]
comp <- mp[grep("Company:", mp$Paragraph), ]
tick <- mp[grep("Ticker:", mp$Paragraph), ]
journ <- mp[grep("Journal Code:", mp$Paragraph), ]
##make vector including IDs of Paragraphs to be dropped
drop_par <- c(lang$Par_ID, publ$Par_ID, classi$Par_ID, subj$Par_ID, indust$Par_ID, geo$Par_ID, pers$Par_ID, comp$Par_ID, tick$Par_ID, journ$Par_ID)
# ##remove irrelevant dataframes
# rm(lang, classi, tick)
##remove these paragraphs from dataset
mp <- mp %>%
filter(!Par_ID %in% drop_par)
rm(drop_par)
##remove paragraphs with less than three words
mp <- mp[grepl('\\w*\\s\\w*\\s\\w*',mp$Paragraph),]
##collapse paragraphs into articles
articles <- aggregate(Paragraph ~ Art_ID, data = mp, FUN = paste, collapse = "")
#merge dataset to get articles df
mp <- subset(mp, select = -c(Paragraph))
mp = mp[!duplicated(mp$Art_ID),]
final_data <- merge(articles, mp, by = "Art_ID")
##rename Paragraph variable into Text
final_data <- rename(final_data, Text = Paragraph) #rename Paragraph value
##remove motherwell headlines
final_data <-
with(final_data, final_data[!grepl(c("Motherwell", "Mothercare"), Headline), ])
##remove unnecessary variables
final_data <- subset(final_data, select = -c(Art_ID, Par_ID, Author, Edition, Graphic, Month, Day, Section, Source_File))
names(final_data)
####!!!!!!! FIX ISSUE: DIFFERENT LENGTH ARTICLES + FINAL DATA
# Save multiple objects
save(final_data, file = "final_data.RData")
load("final_data.RData")
#load packages
library(tidyverse)
library(stm)
library(quanteda)
library(quanteda.textstats)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
#add period
final_data <- final_data %>%
mutate(Period=
ifelse (Year <2005, 1,
ifelse (Year <2010, 2,
ifelse (Year <2015, 3, 4))))
#add column for mother and father
final_data<- final_data %>%
mutate(Headline=tolower(Headline)) %>%
mutate(Mother= str_detect(final_data$Headline, "mother"))
#keep only metadata and texts
data<- final_data %>%
select("Year", "Text", "Newspaper", "Mother")
#remove mother
#data<- data %>%
mutate(Mother = Text = gsub("mother", " ", data$Text))
data<- data %>%
mutate(Text=tolower(Text)) %>%
rowwise() %>%
mutate(Text1=
ifelse(Mother=="TRUE",
gsub("mother", "", Text),
gsub("father", "", Text)))
#create document feature matrix for mother and father separately
m<- data %>%
filter(Mother=="TRUE")
f<- data %>%
filter(Mother=="FALSE")
dfm_prep<- function(x) {
x$Text1%>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens(remove_punc=TRUE) %>%
tokens_remove(stopwords("English")) %>%
tokens_remove(c("said", "like", "just", "can", "go", "one", "say", "also", "want", "told", "get", "say ", "two", "make")) #frequent non interesting words
}
dfmm<- dfm_prep(m) %>%
tokens_wordstem(language = quanteda_options("language_stemmer")) %>%
tokens_remove(c("s")) %>%
dfm() %>%
dfm_trim(min_termfreq = 5)
dfmf<- dfm_prep(f) %>%
tokens_wordstem(language = quanteda_options("language_stemmer")) %>%
tokens_remove(c("s")) %>%
dfm() %>%
dfm_trim(min_termfreq = 5)
#no
freq<- function(x){
a<- x %>% textstat_frequency() %>% head(20)
a$feature<- factor(a$feature, levels=a$feature)
ggplot(a, aes(x=frequency, y=feature, fill=docfreq)) +
geom_col() #+ ggtitle("Most frequent words around the word Mother")
a
ggsave("plot.png", a,  width=2, height=2)
}
#plot for mother
freq<- dfmm %>% textstat_frequency() %>% head(20)
freq$feature<- factor(freq$feature, levels=freq$feature)
a<- ggplot(freq, aes(x=frequency, y=feature, fill=docfreq)) +
geom_col() + ggtitle("Most frequent words around the word Mother")
a
ggsave("dfmm.png", a,  width=2, height=2)
freq<- dfmf %>% textstat_frequency() %>% head(20)
freq$feature<- factor(freq$feature, levels=freq$feature)
a<- ggplot(freq, aes(x=frequency, y=feature, fill=docfreq)) +
geom_col() + ggtitle("Most frequent words around the word Father")
a
ggsave("dfmf.png", a,  width=2, height=2)
which(is.na(data$Year))
data<- na.omit(data)
which(is.na(data$Year))
#try STM
processed <- textProcessor(data$Text1, metadata = data)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta
PrevFit <- stm(documents = out$documents, vocab = out$vocab,
K = 20, prevalence =~ Mother  + Newspaper + Year ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
labelTopics(PrevFit)
topics<-labelTopics(PrevFit, c(1:20))
labelTopics(PrevFit)
#print docs strongly associated with a topic
#don't know if we need it
thoughts17 <- findThoughts(PrevFit, texts = data$Text,  n = 2, topics = 17)$docs[[1]]#Ã¹
thoughts17
out$meta$Mother <- as.factor(out$meta$Mother)
prep <- estimateEffect(1:20 ~ Mother + Newspaper + Year, PrevFit,
meta = out$meta, uncertainty = "Global")
summary(prep, topics=1)
plot(PrevFit, type = "summary", xlim = c(0, .3))
summary(prep, topics=1)
#K = 10
TenFit <- stm(documents = out$documents, vocab = out$vocab,
K = 10, prevalence =~ Mother  + Newspaper + Year ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
labelTopics(TenFit)
#K = 15, tried to run with content covariate but it takes too lomg- francis laptop needs to try if we feel the need
FifFit <- stm(documents = out$documents, vocab = out$vocab,
K = 15, prevalence =~ Mother + Year + Newspaper,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
#load packages
library(tidyverse)
library(stm)
library(quanteda)
library(quanteda.textstats)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
#add period
final_data <- final_data %>%
mutate(Period=
ifelse (Year <2005, 1,
ifelse (Year <2010, 2,
ifelse (Year <2015, 3, 4))))
#add column for mother and father
final_data<- final_data %>%
mutate(Headline=tolower(Headline)) %>%
mutate(Mother= str_detect(final_data$Headline, "mother"))
#keep only metadata and texts
data<- final_data %>%
select("Year", "Text", "Newspaper", "Mother")
#remove mother
#data<- data %>%
mutate(Mother= Text=gsub("mother", " ", data$Text))
#load packages
library(tidyverse)
library(stm)
library(quanteda)
library(quanteda.textstats)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
#add period
final_data <- final_data %>%
mutate(Period=
ifelse (Year <2005, 1,
ifelse (Year <2010, 2,
ifelse (Year <2015, 3, 4))))
#add column for mother and father
final_data<- final_data %>%
mutate(Headline=tolower(Headline)) %>%
mutate(Mother= str_detect(final_data$Headline, "mother"))
#keep only metadata and texts
data<- final_data %>%
select("Year", "Text", "Newspaper", "Mother")
#remove mother
#data<- data %>%
#  mutate(Mother= Text=gsub("mother", " ", data$Text))
data<- data %>%
mutate(Text=tolower(Text)) %>%
rowwise() %>%
mutate(Text1=
ifelse(Mother=="TRUE",
gsub("mother", "", Text),
gsub("father", "", Text)))
#data
which(is.na(data$Year))
data<- na.omit(data)
which(is.na(data$Year))
#try STM
processed <- textProcessor(data$Text1, metadata = data)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta
PrevFit <- stm(documents = out$documents, vocab = out$vocab,
K = 20, prevalence =~ Mother  + Newspaper + Year ,
max.em.its = 75, data = out$meta,
init.type = "Spectral")
labelTopics(PrevFit)
topics<-labelTopics(PrevFit, c(1:20))
?make.heldout
?map
labelTopics(PrevFit)
PrevFit <- stm(documents = out$documents,
vocab = out$vocab,
K = 20,
prevalence =~ Mother  + Newspaper + Year ,
max.em.its = 75,
data = out$meta,
init.type = "Spectral",
seed = TRUE)
labelTopics(PrevFit)
knitr::opts_chunk$set(echo = TRUE)
estimateEffect(prevFit)
load("Data.R")
estimateEffect(PrevFit)
prep <- estimateEffect(1:20 ~ Mother + Newspaper + Year, PrevFit,
meta = out$meta, uncertainty = "Global")
plot.estimateEffect(prep)
plot.estimateEffect(prep ~ Newspaper + Mother + Year)
plot.estimateEffect(~ Newspaper + Mother + Year, prep)
out$meta$Mother <- as.factor(out$meta$Mother)
prep <- estimateEffect(1:20 ~ Mother + Newspaper + Year, PrevFit,
meta = out$meta, uncertainty = "Global")
summary(prep, topics=1)
plot(PrevFit, type = "summary", xlim = c(0, .3))
plot(PrevFit, type = "summary", xlim = c(0, .3), method = difference)
prep <- estimateEffect(1:20 ~ Mother + Newspaper + Year, PrevFit,
meta = out$meta, uncertainty = "Global", method = "difference")
View(prep)
plot(prep,
covariate = "Mother",
topics = c(2, 3, 17),
model = PrevFit,
method = "difference",
cov.value1 = "True", cov.value2 = "False",
main = "Effect of Mother vs. Father",
custom.labels = "Employment", "Royal Family", "Childbirth")
plot(prep,
covariate = "Mother",
topics = c(2, 3, 17),
model = PrevFit,
method = "difference",
cov.value1 = "True", cov.value2 = "False",
main = "Effect of Mother vs. Father",
custom.labels = "Employment", "Royal Family", "Childbirth")
plot(prep,
covariate = "Mother",
topics = c(2, 3, 17),
model = PrevFit,
method = "difference",
cov.value1 = "Mother", cov.value2 = "Father",
main = "Effect of Mother vs. Father",
custom.labels = "Employment", "Royal Family", "Childbirth")
plot(prep, "", method = "continuous", topics = 17, model = PrevFit, printlegend = F, xaxt = "n", xlab = "Years (2000-2019)")
