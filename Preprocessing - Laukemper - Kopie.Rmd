---
title: "Preprocessing - Thesis"
output: html_document
date: "2022-10-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### Header
```{r}
# rm(list=ls()) #empty environment
##load libraries
library(LexisNexisTools)
library(tidyverse)
library(stringi)
```


```{r Import articles}
##import articles
dir("../Data-TAD") #identify where data is saved
data <- lnt_read("../Data-TAD") #individual
length(unique(data@meta$ID)) #4800 documents

save(data, file = "data.RData") #save LNToutput

```

###Load Corpi
```{r}
load(file = "data.RData")
```

###---------------------------Remove direct duplicates

```{r check for missing dates & rm direct duplicates}
nrow(is.na(data@meta$Date)) #check that there are no missing dates
data[duplicated(data@articles$Article), ] #check if there are direct duplicates (there are 52)
data <- data[!duplicated(data@articles$Article), ] #remove direct duplicates
```


###----------------------------Remove indirect duplicates

Why did I get there error meassage: You supplied NA values to dates, when actually no NAs

We manually compared the texts of potential duplicates with various similarity scores. In the end, we decided on a cut-off of 0.95.

```{r}
nrow(is.na(data@meta$Date))
##calculate distance (takes several minutes) - converts into dtm, compares articles published on same day, and calculates overlap
duplicates_data <- lnt_similarity(LNToutput =  data, #this is the same as similarity measure from quanteda, if rel-dist = off
                                      threshold = 0.95,
                                      rel_dist = F) #no Levenstein distance calculated - much faster


#validate
head(duplicates_data[order(duplicates_data$Similarity), ], n = 1)
duplicates_data[11]
```

###REMOVE INDIRECT DUPLICATES (COMMENTED OUT)
```{r}
data <- data[!data@meta$ID %in% duplicates_data$ID_duplicate, ] #remove duplicates
nrow(data) #4617 articles left
head(data@meta)
```
###SAVE Dup removed data
```{r}
save(data, file = "data.RData") #save LNToutput
```


```{r}
load(file = "data.RData")
```


##-----------------------TURN INTO META_Para and META_article dfs
```{r}
data@meta[8,] 
data@meta[data@meta$Newspaper == "March 20, 2009", ] #Times London, Times London, Times London

```
```{r correct Newspaper}
library(tidyverse)
data@meta <- data@meta %>%
    mutate(Newspaper = recode(Newspaper,
"The Guardian(London)" = "The Guardian",            
"The Times (London)" = "The Times",          
"Daily Mail (London)" = "Daily Mail",
"The Guardian (London)" = "The Guardian",
"Guardian.com" = "The Guardian",                        
"DAILY MAIL (London)" = "Daily Mail",              
"The Guardian (London) - Final Edition" = "The Guardian",
"May 4, 2012" = "The Times",          
"The Guardian - Final Edition" = "The Guardian",
"Mail on Sunday (London)" = "Daily Mail",              
"MAIL ON SUNDAY (London)" = "Daily Mail",
"March 20, 2009" = "The Times",          
"MAIL ON SUNDAY" = "Daily Mail",                 
"March 27, 2009" = "The Times",                     
"Guardian.com." = "The Times",                       
"June 21, 2011" = "The Times",                       
"March 26, 2009"= "The Times",                       
"March 25, 2009" = "The Times",                      
"May 22, 2012" = "The Times",                        
"February 13, 2009" = "The Times",                 
"February 17, 2009" = "The Times",                   
"March 5, 2009" = "The Times",                       
"March 18, 2009" = "The Times",                       
"January 21, 2009" = "The Times",                     
"March 13, 2009" = "The Times",                       
"March 20, 2012" = "The Times",                       
"March 24, 2009" = "The Times",                      
"March 9, 2009" = "The Times",                        
"March 15, 2009" = "The Times",                       
"February 12, 2009" = "The Times",                    
"March 22, 2009"= "The Times",                  
"February 18, 2009" = "The Times",                    
"March 21, 2009" = "The Times",                      
"March 15, 2012" = "The Times",                      
"March 16, 2009" = "The Times",                       
"March 17, 2012" = "The Times",                       
"September 9, 2010" = "The Times",                    
"March 8, 2009" = "The Times",                       
"May 25, 2012" = "The Times",
"September 11, 2010" = "The Times",                   
"February 5, 2009" = "The Times",                     
"February 16, 2009" = "The Times",                    
"March 4, 2009" = "The Times",                        
"March 14, 2009" = "The Times",                       
"March 19, 2009" = "The Times",                       
"October 13, 2010" = "The Times",                     
"April 6, 2009" = "The Times"))

unique(data@meta$Newspaper)
```
##-------------------add missing variables
```{r}
data@meta$Date

##Split Year variable
data@meta <- data@meta %>%
  dplyr::mutate(Year = lubridate::year(Date), 
                Month = lubridate::month(Date), 
                Day = lubridate::day(Date))

head(data@paragraphs)

# ##make Paragraph ID
# data$Par_ID <- with(data, paste0(Par_ID, Newspaper, Headline, Year))

# ##drop unnecessary columns
# data <- subset(data, select = -c(Edition, Graphic, Source_File))
```

```{r}
# meta_articles <- lnt_convert(data, to = "data.frame") #keep only one df 
#meta_paragraphs
mp <- lnt_convert(data, to = "data.frame", what = "Paragraphs")
```

##----------------turn paragraphs into single dataframe
```{r}
###update ID variables
# meta_paragraphs$Art_ID <- with(meta_paragraphs, paste0(Art_ID, Newspaper, Headline, Date)) #new ID
# 
# data <- meta_paragraphs
```

##basic data cleaning (removing unnecessary sections)
```{r}


##-------------------- remove irrelavnt infor paragraphs

##make dfs that include relevant paragraphs
lang <- mp[grep("Language:", mp$Paragraph), ]
publ <- mp[grep("Publication-Type:", mp$Paragraph), ]
classi <- mp[grep("Classification", mp$Paragraph), ]
subj <- mp[grep("Subject:", mp$Paragraph), ]
indust <- mp[grep("Industry:", mp$Paragraph), ]
geo <- mp[grep("Geographic:", mp$Paragraph), ]
pers <- mp[grep("Person:", mp$Paragraph), ]
comp <- mp[grep("Company:", mp$Paragraph), ]
tick <- mp[grep("Ticker:", mp$Paragraph), ]
journ <- mp[grep("Journal Code:", mp$Paragraph), ]

##make vector including IDs of Paragraphs to be dropped
drop_par <- c(lang$Par_ID, publ$Par_ID, classi$Par_ID, subj$Par_ID, indust$Par_ID, geo$Par_ID, pers$Par_ID, comp$Par_ID, tick$Par_ID, journ$Par_ID)

# ##remove irrelevant dataframes
# rm(lang, classi, tick)

##remove these paragraphs from dataset 
mp <- mp %>%
  filter(!Par_ID %in% drop_par)

rm(drop_par)


```


```{r collapse paragraphs into article text}
##remove paragraphs with less than three words
mp <- mp[grepl('\\w*\\s\\w*\\s\\w*',mp$Paragraph),]

##collapse paragraphs into articles
articles <- aggregate(Paragraph ~ Art_ID, data = mp, FUN = paste, collapse = "") 

#merge dataset to get articles df
mp <- subset(mp, select = -c(Paragraph))
mp = mp[!duplicated(mp$Art_ID),]
final_data <- merge(articles, mp, by = "Art_ID")

##rename Paragraph variable into Text
final_data <- rename(final_data, Text = Paragraph) #rename Paragraph value

##remove motherwell and mothercare headlines
final_data <- 
  with(final_data, final_data[!grepl(c("Motherwell", "Mothercare"), Headline), ])

##remove unnecessary variables
final_data <- subset(final_data, select = -c(Art_ID, Par_ID, Author, Edition, Graphic, Month, Day, Section, Source_File))
names(final_data)


####!!!!!!! FIX ISSUE: DIFFERENT LENGTH ARTICLES + FINAL DATA
```

```{r}
##make time period variable based on year variable (period: 00, 05, 10, 15)


```



```{r collapse paragraphs into article text}
# Save multiple objects
save(final_data, file = "final_data.RData")
load("final_data.RData")
```




