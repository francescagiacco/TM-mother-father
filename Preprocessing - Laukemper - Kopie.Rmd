---
title: "Preprocessing - Thesis"
output: html_document
date: "2022-10-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### Header
```{r}
# rm(list=ls()) #empty environment
##load libraries
library(LexisNexisTools)
library(tidyverse)
library(stringi)
```


```{r Import articles}
##import articles
dir("../Data-TAD") #identify where data is saved
data <- lnt_read("../Data-TAD") #individual
length(unique(data@meta$ID)) #4800 documents

save(data, file = "data.RData") #save LNToutput

```

###Load Corpi
```{r}
load(file = "data.RData")
```

###---------------------------Remove direct duplicates

```{r check for missing dates & rm direct duplicates}
nrow(is.na(data@meta$Date)) #check that there are no missing dates
data[duplicated(data@articles$Article), ] #check if there are direct duplicates (there are 52)
data <- data[!duplicated(data@articles$Article), ] #remove direct duplicates
```


###----------------------------Remove indirect duplicates

Why did I get there error meassage: You supplied NA values to dates, when actually no NAs

We manually compared the texts of potential duplicates with varius similarity scores. In the end, we decided on a cut-off of 0.95.

```{r}
nrow(is.na(data@meta$Date))
##calculate distance (takes several minutes) - converts into dtm, compares articles published on same day, and calculates overlap
duplicates_data <- lnt_similarity(LNToutput =  data, #this is the same as similarity measure from quanteda, if rel-dist = off
                                      threshold = 0.95,
                                      rel_dist = F) #no Levenstein distance calculated - much faster


#validate
head(duplicates_data[order(duplicates_data$Similarity), ], n = 1)
duplicates_data[11]
```

###REMOVE INDIRECT DUPLICATES (COMMENTED OUT)
```{r}
data <- data[!data@meta$ID %in% duplicates_data$ID_duplicate, ] #remove duplicates
nrow(data) #4617 articles left
head(data@meta)
```
###SAVE Dup removed data
```{r}
save(data, file = "data.RData") #save LNToutput
```


```{r}
load(file = "data.RData")
```


##-----------------------TURN INTO META_Para and META_article dfs
```{r}
data@meta[8,] 
data@meta[data@meta$Newspaper == "May 4, 2012",] #Times London

data@meta[data@meta$Newspaper == "March 20, 2009", ] #Times London, Times London, Times London


dates <- unique(data@meta$Date)
unique(data@meta$Newspaper)

meta_articles <- lnt_convert(data, to = "data.frame") #keep only one df 
meta_paragraphs <- lnt_convert(data, to = "data.frame", what = "Paragraphs")
```


##----------------turn paragraphs into single dataframe
```{r}
###update ID variables
head(meta_paragraphs)
names(meta_paragraphs)
unique(meta_paragraphs$Newspaper)

#new ID
meta_paragraphs$Art_ID <- with(meta_paragraphs, paste0(Art_ID, Newspaper, Headline, Date)) #new ID

data <- meta_paragraphs
```

##-------------------add missing variables
```{r}
unique(data$Newspaper)

#harmonize times of india
data$Newspaper[data$Newspaper %in% c("The Guardian(London)", "The Guardian (London)")] <- "The Guardian"

#harmonize Guardian
data$Newspaper[data$Newspaper %in% c("Times of India (Electronic Edition)", "The Times of India (TOI)")] <- "The Times of India"

#harmonize The Times
data$Newspaper[data$Newspaper %in% c("The Sunday Times (London)", "The Times (London)")] <- "The Times"

##make country variable
India <- c("The Times of India", "The Hindu") 
UK <- c("The Guardian", "The Times")

data$Country <- data$Newspaper
data$Country[data$Country %in% India] <- "India"
data$Country[data$Country %in% UK] <- "UK"

unique(data$Country)

##Split Year variable
data <- data %>%
  dplyr::mutate(Year = lubridate::year(Date), 
                Month = lubridate::month(Date), 
                Day = lubridate::day(Date))

##make Paragraph ID
data$Par_ID <- with(data, paste0(Par_ID, Newspaper, Headline, Year))

##drop unnecessary columns
data <- subset(data, select = -c(Edition, Graphic, Source_File))
```

##basic data cleaning (removing unnecessary sections)
```{r}
##-------------------do some basic data cleaning

##remove formatting issues: \\x95The land or \\x93Unchecked
# step might become unnecessary if I remove pubctuation and numbers for analysis
data$Paragraph <- stri_replace_all(data$Paragraph, "", regex = "\\\\x\\d\\d")

##--------------------extract subject classification info and remove irrelavnt infor paragraphs

##make dfs that include relevant paragraphs
lang <- data[grep("Language:", data$Paragraph), ]
publ <- data[grep("Publication-Type:", data$Paragraph), ]
classi <- data[grep("Classification", data$Paragraph), ]
subj <- data[grep("Subject:", data$Paragraph), ]
indust <- data[grep("Industry:", data$Paragraph), ]
geo <- data[grep("Geographic:", data$Paragraph), ]
pers <- data[grep("Person:", data$Paragraph), ]
comp <- data[grep("Company:", data$Paragraph), ]
tick <- data[grep("Ticker:", data$Paragraph), ]

##make vector including IDs of Paragraphs to be dropped
drop_par <- c(lang$Par_ID, publ$Par_ID, classi$Par_ID, subj$Par_ID, indust$Par_ID, geo$Par_ID, pers$Par_ID, comp$Par_ID, tick$Par_ID)

# ##remove irrelevant dataframes
# rm(lang, classi, tick)

##remove these paragraphs from dataset 
data <- data %>%
  filter(!Par_ID %in% drop_par)

head(data$Paragraph, n = 15)
rm(drop_par) #from assignment for Hindu: always remove first words, written in all Caps (?)
```


##------------------------make subject classification variable
```{r}
##edit df
subj <- rename(subj, Classification = Paragraph) #rename Paragraph value
subj <- subset(subj, select = c(Art_ID, Classification)) #drop irrelevant columns

##clean Classification column

#remove subject tag
subj$Classification <- stri_replace_all(subj$Classification, "", regex = "Subject:") # remove weird formatting
head(subj$Classification)

#trim white spaces
subj$Classification <- stri_trim(subj$Classification)
head(subj)

##merge two df
identical(length(unique(subj$Art_ID)), length(unique(data$Art_ID))) #check for equal amount of Art IDs
data <- merge(data, subj, by = "Art_ID")       # Applying merge() function
head(data)

##could also add other info, e.g. industry, publication, geo, pers e.g -> just make sure to fill NAs

# Save multiple objects
save(data, file = "dataset.RData")
# To load the data again
load("dataset.RData")
```




##----------------aggragate paragraphs into article text
#make df of aggregated paragraphs
#?can I use sth else in collapse, e.g. \n to allow quanteda to reshape from text to paragraph
articles <- aggregate(Paragraph ~ Art_ID, data = data, FUN = paste, collapse = "")

#rename Paragraph variable into Text
articles <- rename(articles, Text = Paragraph) #rename Paragraph value

#make dataset for merger with only one row per Art_ID
data2 <- subset(data, select = -c(Paragraph))
data2 = data2[!duplicated(data2$Art_ID),]

#merge dataset to get articles df
articles <- merge(articles, data2, by = "Art_ID")

rm(data2) #remove unnecessary df
para <- data #rename paragraphs df
rm (data)

head(articles$Text, n =1)

rm(comp, geo, inust, pers, publ, subj, subj2, indust)


##----------------------------filter out articles where classifier includes only regulation
tags <- c("GLOBAL WARMING" , "CLIMATOLOGY" , "CLIMATE CHANGE" ,  "GREENHOUSE GASES" , "WILDFIRES" , "FIRES" , "FOREST FIRES" , "NATURAL DISASTERS" , "DROUGHT" , "WEATHER EVENTS" , "HEAT WAVES" , "SEVERE WEATHER" , "NATURAL DISASTERS" , "SUSTAINABILITY" , "EXTREME TEMPERATURES" , "FLOODS" , "ECOSYSTEMS" , "COASTAL AREAS " , " INFECTIOUS DISEASE " , " PUBLIC HEALTH " , " POLLUTION " , " NEGATIVE ENVIRONMENTAL NEWS " , " IRRIGATION")

art_reg <- 
  with(articles, articles[grepl("REGULATION & POLICY", Classification) & 
                      !grepl(paste(tags, collapse = "|"), Classification), ])

art_reg$Classification

##removes articles with e.g. tag "immigration regulation & policy"

##eyeball test confirmed: articles are not on climate change / high error rate

##how many articles will be dropped by newspaper?
a <- table(art_reg$Newspaper) #is it because of electronic vs.?
a

##220 articles in total
#The Hindu: 10
#NYT: 142
#TOI: 55
#USA Today

##remove these texts from articles and paragraphs datasets
articles <- articles %>%
  filter(!Art_ID %in% art_reg$Art_ID)

para <- para %>%
  filter(!Art_ID %in% art_reg$Art_ID)

names(para)
rm(art_reg)

# Save multiple objects
save(articles, para, file = "Data/artpara.RData")
# To load the data again
load("Data/artpara.RData")

#save articles as csv
write.csv(articles,"Data/articles.csv", row.names = T)




